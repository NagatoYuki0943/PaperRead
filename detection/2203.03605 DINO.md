# 主要内容

## 结构

![image-20240229085359158](2203.03605%20DINO.assets/DINO architecture.png)

作为类似 DETR 的模型，DINO 包含主干、多层 Transformer 编码器、多层 Transformer 解码器和多个预测头。

改进主要是在 Transformer 编码器和解码器上。选择最后一层中的前 K 个编码器特征来初始化 Transformer 解码器的位置查询，而内容查询则保留为可学习参数。我们的解码器还包含一个包含正样本和负样本的对比降噪 (CDN) 部分。

### 动态锚框

![Mixed Query Selection](2203.03605%20DINO.assets/Mixed%20Query%20Selection.png)

三种不同查询初始化方法的比较。术语“静态”意味着它们在推理中对于不同的图像将保持相同。这些静态查询的常见实现是使它们可学习。

DAB-DETR 明确地将 DETR 中的每个位置查询表示为 4D 锚框 (x, y, w, h)，其中 x 和 y 是框的中心坐标，w 和 h 对应于其宽度和高度。这种显式的锚框公式使得在解码中可以轻松地逐层动态细化锚框。

 遵循 DAB-DETR，将解码器中的查询制定为动态锚框，并跨解码器层逐步细化它们。查询的动态锚框公式将类似 DETR 的模型与经典的两阶段模型联系起来。因此，我们提出了一种混合查询选择方法，这有助于更好地初始化查询。我们从编码器的输出中选择初始锚框作为位置查询。然而，我们像以前一样让内容查询可学习，鼓励第一个解码器层关注空间先验。

在 DETR 和 DN-DETR 中，解码器查询是静态嵌入，无需从单个图像中获取任何编码器特征，如上图（a）所示。他们直接从训练数据中学习锚点（在 DN-DETR 和 DAB-DETR 中）或位置查询（在 DETR 中），并将内容查询设置为全 0 向量。Deformable DETR 学习位置查询和内容查询，这是静态查询初始化的另一种实现。为了进一步提高性能，Deformable DETR 有一个查询选择变体（在[41]中称为“两阶段”），它从最后一个编码器层的输出中选择前 K 个特征作为先验来增强解码器查询。如上图 (b) 所示，位置查询和内容查询都是通过所选特征的线性变换生成的。此外，这些选定的特征被送入辅助检测头以获得预测框，该预测框用于初始化参考框。类似地，Efficient DETR 还根据每个编码器特征的物体（类别）得分来选择前 K 个特征。

我们模型中查询的动态 4D 锚框公式使其与解码器位置查询密切相关，可以通过查询选择来改进。我们遵循上述实践，提出了一种混合查询选择方法。**如上图 (c) 所示，我们仅使用与所选 top-K 个特征相关的位置信息来初始化锚框，但像以前一样将内容查询保持静态**。请注意，Deformable DETR 利用 top-K 特征不仅增强了位置查询，还增强了内容查询。由于所选特征是未经进一步细化的初步内容特征，因此它们可能是含糊不清的并且会误导解码器。例如，选定的特征可能包含多个对象或仅是对象的一部分。相比之下，我们的混合查询选择方法仅通过 top-K 个选定特征增强位置查询，并保持内容查询像以前一样可学习。它帮助模型使用更好的位置信息从编码器中池化更全面的内容特征。

### 对比去噪训练

![Contrastive DeNoising Training](2203.03605%20DINO.assets/Contrastive%20DeNoising%20Training.png)

CDN 群组结构及正反例展示。虽然正例和负例都是 4D 锚点，可以表示为 4D 空间中的点，但为了简单起见，我们将它们说明为同心正方形上的 2D 空间中的点。假设正方形中心是一个GT盒子，内部正方形内部的点被视为正例，内部正方形和外部正方形之间的点被视为负例。

**DN-DETR 引入了一种去噪（DN）训练方法来加速类 DETR 模型的训练收敛**。结果表明 DETR 收敛速度慢的问题是由二分匹配的不稳定引起的。为了缓解这个问题，DN-DETR 建议额外将添加噪声的真实 (GT) 标签和框输入 Transformer 解码器，并训练模型以重建真实标签和框。遵循 DN-DETR，我们将带有噪声的真实标签和框添加到 Transformer 解码器层中，以帮助在训练期间稳定二分匹配。

**为了改善一对一匹配，我们提出了通过同时向真实框添加正样本和负样本的对比去噪训练。将两种不同的噪声添加到同一个真实框后，我们将噪声较小的框标记为正，将另一个标记为负。对比去噪训练有助于模型避免同一目标的重复输出。**

每个 CDN 组都有一组正查询和负查询。如果图像有 n 个 GT 框，则 CDN 组将有 2 × n 个查询，每个 GT 框生成一个正查询和一个负查询。与 DN-DETR 类似，我们也使用多个 CDN 组来提高我们方法的有效性。

### 可变形注意力

**采用 Deformable DETR 中的可变形注意力来提高其计算效率。**

Deformable DETR 是一项加速 DETR 收敛的早期工作。它预测 2D 锚点并设计一个可变形注意力模块。为了计算可变形注意力，它引入了参考点的概念，以便可变形注意力可以关注参考周围的一小组关键采样点。参考点概念使得开发多种技术以进一步提高 DETR 性能成为可能。

### 前向两次

![Look Forward Twice](2203.03605%20DINO.assets/Look%20Forward%20Twice.png)

我们在本节中提出了一种新的框预测方法。Deformable DETR 中的迭代框细化会阻止梯度反向传播以稳定训练。我们将该方法命名为“前向一次”，因为第 $i$ 层的参数仅根据框 $b_i$ 的辅助损失进行更新，如上图(a)示。然而，我们推测来自后面一层的改进的框信息可能更有助于纠正其相邻的早期层中的框预测。因此，我们提出了另一种称为两次预测的方法来执行框更新，其中第i层的参数受到第 $i$ 层和第 $(i+1)$ 层损失的影响，如上图(b)所示。对于每个预测的偏移量 $Δb_i$ ，它将用于更新框两次，一次更新 $b_i^′$，另一次更新 $b_{i+1}^{(pred)}$，因此我们将我们的方法命名为前向两次。

